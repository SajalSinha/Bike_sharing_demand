{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajalSinha/Bike_sharing_demand/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jiangqn/IAN-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1AOFHhVt26x",
        "outputId": "8ed3b629-8a40-45b0-e613-5553569d0062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IAN-pytorch'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Total 63 (delta 0), reused 0 (delta 0), pack-reused 63\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, query_size, key_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.rand(key_size, query_size) * 0.2 - 0.1)\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, query, key, mask):\n",
        "        # query: (batch_size, query_size)\n",
        "        # key: (batch_size, time_step, key_size)\n",
        "        # value: (batch_size, time_step, value_size)\n",
        "        # mask: (batch_size, time_step)\n",
        "        batch_size = key.size(0)\n",
        "        time_step = key.size(1)\n",
        "        weights = self.weights.repeat(batch_size, 1, 1) # (batch_size, key_size, query_size)\n",
        "        query = query.unsqueeze(-1)    # (batch_size, query_size, 1)\n",
        "        mids = weights.matmul(query)    # (batch_size, key_size, 1)\n",
        "        mids = mids.repeat(time_step, 1, 1, 1).transpose(0, 1) # (batch_size, time_step, key_size, 1)\n",
        "        key = key.unsqueeze(-2)    # (batch_size, time_step, 1, key_size)\n",
        "        scores = torch.tanh(key.matmul(mids).squeeze() + self.bias)   # (batch_size, time_step, 1, 1)\n",
        "        scores = scores.squeeze()   # (batch_size, time_step)\n",
        "        scores = scores - scores.max(dim=1, keepdim=True)[0]\n",
        "        scores = torch.exp(scores) * mask\n",
        "        attn_weights = scores / scores.sum(dim=1, keepdim=True)\n",
        "        return attn_weights\n",
        "\n",
        "class IAN(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(IAN, self).__init__()\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.n_class = config.n_class\n",
        "        self.l2_reg = config.l2_reg\n",
        "        self.max_aspect_len = config.max_aspect_len\n",
        "        self.max_context_len = config.max_context_len\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embedding_size)\n",
        "        self.aspect_lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, batch_first=True)\n",
        "        self.context_lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, batch_first=True)\n",
        "        self.aspect_attn = Attention(self.hidden_size, self.hidden_size)\n",
        "        self.context_attn = Attention(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.fc = nn.Linear(self.hidden_size * 2, self.n_class)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(config.embedding))\n",
        "\n",
        "    def forward(self, aspect, context, aspect_mask, context_mask):\n",
        "        aspect = self.embedding(aspect)\n",
        "        aspect = self.dropout(aspect)\n",
        "        aspect_output, _ = self.aspect_lstm(aspect)\n",
        "        aspect_output = aspect_output * aspect_mask.unsqueeze(-1)\n",
        "        aspect_avg = aspect_output.sum(dim=1, keepdim=False) / aspect_mask.sum(dim=1, keepdim=True)\n",
        "        context = self.embedding(context)\n",
        "        context = self.dropout(context)\n",
        "        context_output, _ = self.context_lstm(context)\n",
        "        context_output = context_output * context_mask.unsqueeze(-1)\n",
        "        context_avg = context_output.sum(dim=1, keepdim=False) / context_mask.sum(dim=1, keepdim=True)\n",
        "        aspect_attn = self.aspect_attn(context_avg, aspect_output, aspect_mask).unsqueeze(1)\n",
        "        aspect_features = aspect_attn.matmul(aspect_output).squeeze()\n",
        "        context_attn = self.context_attn(aspect_avg, context_output, context_mask).unsqueeze(1)\n",
        "        context_features = context_attn.matmul(context_output).squeeze()\n",
        "        features = torch.cat([aspect_features, context_features], dim=1)\n",
        "        features = self.dropout(features)\n",
        "        output = self.fc(features)\n",
        "        output = torch.tanh(output)\n",
        "        return output\n",
        "\n",
        "class IanDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path):\n",
        "        data = np.load(path)\n",
        "        self.aspects = torch.from_numpy(data['aspects']).long()\n",
        "        self.contexts = torch.from_numpy(data['contexts']).long()\n",
        "        self.labels = torch.from_numpy(data['labels']).long()\n",
        "        self.aspect_lens = torch.from_numpy(data['aspect_lens']).long()\n",
        "        self.context_lens = torch.from_numpy(data['context_lens']).long()\n",
        "        self.len = self.labels.shape[0]\n",
        "        aspect_max_len = self.aspects.size(1)\n",
        "        context_max_len = self.contexts.size(1)\n",
        "        self.aspect_mask = torch.zeros(aspect_max_len, aspect_max_len)\n",
        "        self.context_mask = torch.zeros(context_max_len, context_max_len)\n",
        "        for i in range(aspect_max_len):\n",
        "            self.aspect_mask[i, 0:i + 1] = 1\n",
        "        for i in range(context_max_len):\n",
        "            self.context_mask[i, 0:i + 1] = 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.aspects[index], self.contexts[index], self.labels[index], \\\n",
        "               self.aspect_mask[self.aspect_lens[index] - 1], self.context_mask[self.context_lens[index] - 1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "4AHV9Joradt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ast\n",
        "import spacy\n",
        "import numpy as np\n",
        "from errno import ENOENT\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_data_info(dataset, pre_processed):\n",
        "    train_fname = dataset + 'train.txt'\n",
        "    test_fname = dataset + 'test.txt'\n",
        "    save_fname = dataset + 'data_info.txt'\n",
        "\n",
        "    word2id, max_aspect_len, max_context_len = {}, 0, 0\n",
        "    word2id['<pad>'] = 0\n",
        "    if pre_processed:\n",
        "        if not os.path.isfile(save_fname):\n",
        "            raise IOError(ENOENT, 'Not a file', save_fname)\n",
        "        with open(save_fname, 'r') as f:\n",
        "            for line in f:\n",
        "                content = line.strip().split()\n",
        "                if len(content) == 3:\n",
        "                    max_aspect_len = int(content[1])\n",
        "                    max_context_len = int(content[2])\n",
        "                else:\n",
        "                    word2id[content[0]] = int(content[1])\n",
        "    else:\n",
        "        if not os.path.isfile(train_fname):\n",
        "            raise IOError(ENOENT, 'Not a file', train_fname)\n",
        "        if not os.path.isfile(test_fname):\n",
        "            raise IOError(ENOENT, 'Not a file', test_fname)\n",
        "\n",
        "        words = []\n",
        "\n",
        "        lines = open(train_fname, 'r').readlines()\n",
        "        for i in range(0, len(lines), 3):\n",
        "            sptoks = nlp(lines[i].strip())\n",
        "            words.extend([sp.text.lower() for sp in sptoks])\n",
        "            if len(sptoks) - 1 > max_context_len:\n",
        "                max_context_len = len(sptoks) - 1\n",
        "            sptoks = nlp(lines[i + 1].strip())\n",
        "            if len(sptoks) > max_aspect_len:\n",
        "                max_aspect_len = len(sptoks)\n",
        "            words.extend([sp.text.lower() for sp in sptoks])\n",
        "        word_count = Counter(words).most_common()\n",
        "        for word, _ in word_count:\n",
        "            if word not in word2id and ' ' not in word and '\\n' not in word and 'aspect_term' not in word:\n",
        "                word2id[word] = len(word2id)\n",
        "\n",
        "        lines = open(test_fname, 'r').readlines()\n",
        "        for i in range(0, len(lines), 3):\n",
        "            sptoks = nlp(lines[i].strip())\n",
        "            words.extend([sp.text.lower() for sp in sptoks])\n",
        "            if len(sptoks) - 1 > max_context_len:\n",
        "                max_context_len = len(sptoks) - 1\n",
        "            sptoks = nlp(lines[i + 1].strip())\n",
        "            if len(sptoks) > max_aspect_len:\n",
        "                max_aspect_len = len(sptoks)\n",
        "            words.extend([sp.text.lower() for sp in sptoks])\n",
        "        word_count = Counter(words).most_common()\n",
        "        for word, _ in word_count:\n",
        "            if word not in word2id and ' ' not in word and '\\n' not in word and 'aspect_term' not in word:\n",
        "                word2id[word] = len(word2id)\n",
        "\n",
        "        with open(save_fname, 'w') as f:\n",
        "            f.write('length %s %s\\n' % (max_aspect_len, max_context_len))\n",
        "            for key, value in word2id.items():\n",
        "                f.write('%s %s\\n' % (key, value))\n",
        "\n",
        "    print('There are %s words in the dataset, the max length of aspect is %s, and the max length of context is %s' % (\n",
        "    len(word2id), max_aspect_len, max_context_len))\n",
        "    return word2id, max_aspect_len, max_context_len\n",
        "\n",
        "\n",
        "def read_data(word2id, max_aspect_len, max_context_len, dataset, pre_processed):\n",
        "    fname = dataset + '.txt'\n",
        "    save_fname = dataset + '.npz'\n",
        "\n",
        "    if pre_processed:\n",
        "        if not os.path.isfile(save_fname):\n",
        "            raise IOError(ENOENT, 'Not a file', save_fname)\n",
        "        return save_fname\n",
        "    else:\n",
        "        aspects, contexts, labels, aspect_lens, context_lens = list(), list(), list(), list(), list()\n",
        "        if not os.path.isfile(fname):\n",
        "            raise IOError(ENOENT, 'Not a file', fname)\n",
        "        lines = open(fname, 'r').readlines()\n",
        "        for i in range(0, len(lines), 3):\n",
        "            polarity = lines[i + 2].split()[0]\n",
        "            if polarity == 'conflict':\n",
        "                continue\n",
        "\n",
        "            context_sptoks = nlp(lines[i].strip())\n",
        "            context = []\n",
        "            for sptok in context_sptoks:\n",
        "                if sptok.text.lower() in word2id:\n",
        "                    context.append(word2id[sptok.text.lower()])\n",
        "\n",
        "            aspect_sptoks = nlp(lines[i + 1].strip())\n",
        "            aspect = []\n",
        "            for aspect_sptok in aspect_sptoks:\n",
        "                if aspect_sptok.text.lower() in word2id:\n",
        "                    aspect.append(word2id[aspect_sptok.text.lower()])\n",
        "\n",
        "            aspects.append(aspect + [0] * (max_aspect_len - len(aspect)))\n",
        "            contexts.append(context + [0] * (max_context_len - len(context)))\n",
        "            if polarity == 'negative':\n",
        "                labels.append(0)\n",
        "            elif polarity == 'neutral':\n",
        "                labels.append(1)\n",
        "            elif polarity == 'positive':\n",
        "                labels.append(2)\n",
        "            aspect_lens.append(len(aspect_sptoks))\n",
        "            context_lens.append(len(context_sptoks) - 1)\n",
        "        print(\"Read %s examples from %s\" % (len(aspects), fname))\n",
        "        aspects = np.asarray(aspects)\n",
        "        contexts = np.asarray(contexts)\n",
        "        labels = np.asarray(labels)\n",
        "        aspect_lens = np.asarray(aspect_lens)\n",
        "        context_lens = np.asarray(context_lens)\n",
        "        np.savez(save_fname, aspects=aspects, contexts=contexts, labels=labels, aspect_lens=aspect_lens, context_lens=context_lens)\n",
        "        return save_fname\n",
        "\n",
        "def load_word_embeddings(fname, embedding_dim, word2id):\n",
        "    if not os.path.isfile(fname):\n",
        "        raise IOError(ENOENT, 'Not a file', fname)\n",
        "\n",
        "    word2vec = np.random.uniform(-0.01, 0.01, [len(word2id), embedding_dim])\n",
        "    oov = len(word2id)\n",
        "    with open(fname, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            if content[0] in word2id:\n",
        "                word2vec[word2id[content[0]]] = np.array(list(map(float, content[1:])))\n",
        "                oov = oov - 1\n",
        "    word2vec[word2id['<pad>'], :] = 0\n",
        "    print('There are %s words in vocabulary and %s words out of vocabulary' % (len(word2id) - oov, oov))\n",
        "    return word2vec"
      ],
      "metadata": {
        "id": "kTD98eCjtnPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import os\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--embedding_size', default=300)\n",
        "parser.add_argument('--batch_size', default=128)\n",
        "parser.add_argument('--n_epoch', default=10)\n",
        "parser.add_argument('--hidden_size', default=300)\n",
        "parser.add_argument('--n_class', default=3)\n",
        "parser.add_argument('--pre_processed', default=True)\n",
        "parser.add_argument('--learning_rate', default=0.001)\n",
        "parser.add_argument('--l2_reg', default=0)\n",
        "parser.add_argument('--clip', default=3.0)\n",
        "parser.add_argument('--dropout', default=0.01)\n",
        "parser.add_argument('--max_aspect_len', default=0)\n",
        "parser.add_argument('--max_context_len', default=0)\n",
        "parser.add_argument('--dataset', default='/content/IAN-pytorch/data/restaurant')\n",
        "parser.add_argument('--embedding_file_name', default='/content/drive/MyDrive/AspectExtraction/glove.840B.300d.txt')\n",
        "parser.add_argument('--embedding', default=0)\n",
        "parser.add_argument('--vocab_size', default=0)\n",
        "\n",
        "config = parser.parse_args()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "0-a1O7EluBzf",
        "outputId": "a00f3a99-9b2d-460a-b535-b9a89b3cb103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--embedding_size EMBEDDING_SIZE]\n",
            "                             [--batch_size BATCH_SIZE] [--n_epoch N_EPOCH]\n",
            "                             [--hidden_size HIDDEN_SIZE] [--n_class N_CLASS]\n",
            "                             [--pre_processed PRE_PROCESSED]\n",
            "                             [--learning_rate LEARNING_RATE] [--l2_reg L2_REG]\n",
            "                             [--clip CLIP] [--dropout DROPOUT]\n",
            "                             [--max_aspect_len MAX_ASPECT_LEN]\n",
            "                             [--max_context_len MAX_CONTEXT_LEN]\n",
            "                             [--dataset DATASET]\n",
            "                             [--embedding_file_name EMBEDDING_FILE_NAME]\n",
            "                             [--embedding EMBEDDING] [--vocab_size VOCAB_SIZE]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-d78e489e-b6d0-4766-9174-019eb6ce79dc.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    start_time = time.time()\n",
        "    print('Loading data info ...')\n",
        "    word2id, config.max_aspect_len, config.max_context_len = get_data_info(config.dataset, config.pre_processed)\n",
        "    config.vocab_size = len(word2id)\n",
        "    train_data = read_data(word2id, config.max_aspect_len, config.max_context_len, config.dataset + 'train',\n",
        "                           config.pre_processed)\n",
        "    test_data = read_data(word2id, config.max_aspect_len, config.max_context_len, config.dataset + 'test',\n",
        "                          config.pre_processed)\n",
        "    print('Loading pre-trained word vectors ...')\n",
        "    config.embedding = load_word_embeddings(config.embedding_file_name, config.embedding_size, word2id)\n",
        "    train_dataset = IanDataset(train_data)\n",
        "    test_dataset = IanDataset(test_data)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "    model = IAN(config).cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.l2_reg)\n",
        "    max_acc = 0\n",
        "    for epoch in range(config.n_epoch):\n",
        "        train_total_cases = 0\n",
        "        train_correct_cases = 0\n",
        "        for data in train_loader:\n",
        "            aspects, contexts, labels, aspect_masks, context_masks = data\n",
        "            aspects, contexts, labels = aspects.cuda(), contexts.cuda(), labels.cuda()\n",
        "            aspect_masks, context_masks = aspect_masks.cuda(), context_masks.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(aspects, contexts, aspect_masks, context_masks)\n",
        "            _, predicts = outputs.max(dim=1)\n",
        "            train_total_cases += labels.shape[0]\n",
        "            train_correct_cases += (predicts == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), config.clip)\n",
        "            optimizer.step()\n",
        "        train_accuracy = train_correct_cases / train_total_cases\n",
        "        test_total_cases = 0\n",
        "        test_correct_cases = 0\n",
        "        for data in test_loader:\n",
        "            aspects, contexts, labels, aspect_masks, context_masks = data\n",
        "            aspects, contexts, labels = aspects.cuda(), contexts.cuda(), labels.cuda()\n",
        "            aspect_masks, context_masks = aspect_masks.cuda(), context_masks.cuda()\n",
        "            outputs = model(aspects, contexts, aspect_masks, context_masks)\n",
        "            _, predicts = outputs.max(dim=1)\n",
        "            test_total_cases += labels.shape[0]\n",
        "            test_correct_cases += (predicts == labels).sum().item()\n",
        "        test_accuracy = test_correct_cases / test_total_cases\n",
        "        print('[epoch %03d] train accuracy: %.4f test accuracy: %.4f' % (epoch, train_accuracy, test_accuracy))\n",
        "        max_acc = max(max_acc, test_accuracy)\n",
        "    print('max test accuracy:', max_acc)\n",
        "    end_time = time.time()\n",
        "    print('Time Costing: %s' % (end_time - start_time))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "ISNLLAYzuG8X",
        "outputId": "ce8896c6-6b5f-4bcc-cbcb-6dab9b7f59e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data info ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0018b7bfcca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-0018b7bfcca9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading data info ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mword2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_aspect_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_context_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     train_data = read_data(word2id, config.max_aspect_len, config.max_context_len, config.dataset + 'train',\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KxwGULEWwyKa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}